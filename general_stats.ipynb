{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95155ead-60d5-449b-88e5-83af88a96aff",
   "metadata": {},
   "source": [
    "<h1> Quantitative Analysis </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3476e65f-223d-46e7-b9b3-65378a138c10",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd8f20-6949-4bd4-a118-56344e73210f",
   "metadata": {},
   "source": [
    "<h2> Preprocessing Steps </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59feb18b-ca3e-44f3-a6b6-5d423176a308",
   "metadata": {},
   "source": [
    "<h4>Step 1</h4>\n",
    "\n",
    "Read data into Pandas dataframe and examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4419ed-79bf-462f-8d79-836b7ac158ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   letter  year language\n",
      "arc71   Mercredi 29 septembre 1915\\nMa chère Louisette...  1915   french\n",
      "hl_02   Correspondance militaire adressée à monsieur J...  1914   french\n",
      "hl_03a  Chère femme, mes deux gosses ainsi que toute m...  1914   french\n",
      "hl_03b  Chers Mère et frère,\\n\\nTout ce que je vous re...  1914   french\n",
      "hl_04   Aux armées le 27 mai 1916\\n\\n \\nChers parents,...  1916   french \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 55 entries, arc71 to na_uk_40\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   letter    55 non-null     object\n",
      " 1   year      55 non-null     int64 \n",
      " 2   language  55 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def load_json_to_df(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes a file path, opens the .json file at\n",
    "    that position, and transforms it into a dataframe\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "        return pd.DataFrame({\n",
    "            \"letter\": json_data.values()\n",
    "        }, index = json_data.keys())\n",
    "\n",
    "DATA_DIR = Path.cwd() / \"data\"\n",
    "KAGGLE_FILE_PATH = DATA_DIR / \"ww1letters.json\"\n",
    "KAGGLE_METADATA_PATH = DATA_DIR / \"index.csv\"\n",
    "\n",
    "kaggle_df = load_json_to_df(KAGGLE_FILE_PATH)\n",
    "with open(KAGGLE_METADATA_PATH, 'r') as f:\n",
    "    metadata_df = pd.read_csv(f)\n",
    "    metadata_df.index = metadata_df[\"letter_key\"]\n",
    "\n",
    "kaggle_df = kaggle_df.join(\n",
    "    metadata_df[[\"year\", \"language\"]],\n",
    ")\n",
    "kaggle_df = kaggle_df[kaggle_df[\"year\"].notna()].astype({\"year\": \"int64\"})\n",
    "kaggle_df[\"language\"] = kaggle_df[\"language\"].fillna(\"english\")\n",
    "\n",
    "print(kaggle_df.head(), \"\\n\")\n",
    "print(kaggle_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc0abd5-e98f-473f-bffc-ac3639c92643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  letter  year\n",
      "lo001  Dear Ginger, I have just returned from a holid...  1915\n",
      "lo002  Zeppelins over London 4th Nov 1915 David to Gi...  1915\n",
      "lo003  David Joins Army 28 Dec 1915 David to Ginger D...  1915\n",
      "lo004  How Britain Prepared Ginger (Ethel)  to David ...  1916\n",
      "lo005  1916 OTC Gidea Park David to Ginger (sister Et...  1916 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 367 entries, lo001 to sh015\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  367 non-null    object\n",
      " 1   year    367 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "DEAREST_PATH = DATA_DIR / \"400_letters.json\"\n",
    "\n",
    "dearest_df = load_json_to_df(DEAREST_PATH)\n",
    "\n",
    "london_years = [1915] * 3 + [1916] * 6\n",
    "france_years = [1917] * 77\n",
    "missing_years = [1917] * 13\n",
    "pow_years = [1918] * 174 + [1917] * 79\n",
    "sheerness_years = [1919] * 15\n",
    "\n",
    "dearest_df[\"year\"] = london_years + france_years + missing_years + pow_years + sheerness_years\n",
    "print(dearest_df.head(), \"\\n\")\n",
    "print(dearest_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fade4a8-43fd-46d4-bac1-d2e88ee729a7",
   "metadata": {},
   "source": [
    "<h4>Step 2</h4>\n",
    "\n",
    "Retrieve English letters and apply tokenisation, lemmatisation, other steps?\n",
    "\n",
    "How to deal with French letters?\n",
    "\n",
    "We'll also explain more steps here.\n",
    "\n",
    "credits to notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7177ee4a-6f91-4321-b42d-33510e3f966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "\n",
    "STEMMER = nltk.stem.WordNetLemmatizer()\n",
    "un_to_wn_map = {\"VERB\" : wordnet.VERB,\n",
    "                \"NOUN\" : wordnet.NOUN,\n",
    "                \"ADJ\" : wordnet.ADJ,\n",
    "                \"ADV\" : wordnet.ADV}\n",
    "STOP = set(stopwords.words(\"english\")).union({'’', '“', '”', '[', ']', '…'})\n",
    "\n",
    "english_kaggle = kaggle_df[\"letter\"][kaggle_df[\"language\"] == \"english\"]\n",
    "# print(english_kaggle)\n",
    "\n",
    "def preprocess(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Takes a series of letters and preprocesses them\n",
    "    by applying tokenisation, \n",
    "    \"\"\"\n",
    "    letters_preprocessed = []\n",
    "    for letter in df:\n",
    "        letter_tokens = nltk.tokenize.word_tokenize(letter.lower())\n",
    "        letter_tagged = nltk.pos_tag(letter_tokens, tagset = \"universal\")\n",
    "        letter_lemmas = []\n",
    "        \n",
    "        for (token, pos) in letter_tagged:\n",
    "            if token not in STOP:\n",
    "                if pos in un_to_wn_map.keys():\n",
    "                    letter_lemmas.append(STEMMER.lemmatize(token,\n",
    "                                                           pos = un_to_wn_map[pos]))\n",
    "                elif token.isalnum():\n",
    "                    letter_lemmas.append(STEMMER.lemmatize(token))\n",
    "    \n",
    "        letters_preprocessed.append(' '.join(letter_lemmas))\n",
    "\n",
    "    return letters_preprocessed\n",
    "\n",
    "english_kaggle_pp = preprocess(english_kaggle)\n",
    "dearest_pp = preprocess(dearest_df[\"letter\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60777cdd-416a-4aa4-a1d3-1951b75aa790",
   "metadata": {},
   "source": [
    "<h4>Step 3</h4>\n",
    "\n",
    "Replace the letters in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5295b135-33ca-4a85-9554-9fbd5f1edfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  letter  year\n",
      "lo001  dear ginger return holiday brighton glorious t...  1915\n",
      "lo002  zeppelin london 4th nov 1915 david ginger 56 r...  1915\n",
      "lo003  david join army 28 dec 1915 david ginger dec 2...  1915\n",
      "lo004  britain prepared ginger ethel david somewhere ...  1916\n",
      "lo005  1916 otc gidea park david ginger sister ethel ...  1916 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 403 entries, lo001 to na_uk_40\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  403 non-null    object\n",
      " 1   year    403 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "english_data_df = kaggle_df[kaggle_df[\"language\"] == \"english\"].copy()\n",
    "english_data_df = english_data_df.drop(columns = [\"language\"])\n",
    "english_data_df[\"letter\"] = english_kaggle_pp\n",
    "\n",
    "dearest_df[\"letter\"] = dearest_pp\n",
    "\n",
    "data_df = pd.concat([dearest_df, english_data_df], ignore_index = False)\n",
    "\n",
    "print(data_df.head(), \"\\n\")\n",
    "print(data_df.info())\n",
    "\n",
    "data_df.to_csv(DATA_DIR / \"preprocessed_letters.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5196b4-b9aa-466c-85ca-32d71fb150dd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb5d805-5363-4fa5-9751-a14401db3e74",
   "metadata": {},
   "source": [
    "<h2>General Statistics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e353719-efb3-423a-803f-c3f28b3203b5",
   "metadata": {},
   "source": [
    "<h4>ugh</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a246d878-f2be-42de-91f5-bb1f85be52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "english_letters = pd.read_csv(DATA_DIR / \"preprocessed_letters.csv\")[\"letter\"]\n",
    "\n",
    "def letter_stats(letter: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    Takes in a letter and calculates its key characteristics\n",
    "    \"\"\"\n",
    "    text_size = len(letter)\n",
    "    vocab_size = len(set(letter))\n",
    "    ttr = vocab_size / text_size\n",
    "\n",
    "    return ttr\n",
    "\n",
    "def show_letter_stats(letters: list[list[str]]) -> (list[float]):\n",
    "    \"\"\"\n",
    "    Show stuff\n",
    "    \"\"\"\n",
    "    for letter in letters:\n",
    "        ttr = letter_stats(letter)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
