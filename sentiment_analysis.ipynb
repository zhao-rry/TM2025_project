{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "97c5f53c-7a8f-4655-bb80-a303ca0a8152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.11)\n",
      "Path to model files: C:\\Users\\kevin\\.cache\\kagglehub\\models\\omlande\\bert-multiclassification-sentiment-analysis\\pyTorch\\default\\1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nModelConfigPath = path + \"\\\\bert_emotion_classifier\"\\nModelConfig = json.loads(ModelPath)\\nTokenizerPath = ModelPath + \"\\\\tokenizer_config.json\"\\nTokenizerConfig = json.loads(TokenizerPath)\\n'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "import json\n",
    "from transformers import AutoConfig, BertModel, PreTrainedTokenizer, BertConfig, AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.model_download(\"omlande/bert-multiclassification-sentiment-analysis/pyTorch/default\")\n",
    "print(\"Path to model files:\", path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert_emotion_classifier\")\n",
    "model = BertModel.from_pretrained(\"bert_emotion_classifier\", use_safetensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6536010f-eb9d-4600-bbf7-299a3b9d2748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f01bf4b1-9c50-4fda-93a4-af2085faa50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word, layer_nums):\n",
    "    # Tokenize the word into subtokens and add special tokens [CLS] and [SEP]\n",
    "    subtokens = [tokenizer.cls_token] + tokenizer.tokenize(word) + [tokenizer.sep_token]\n",
    "    # Convert subtokens to input IDs\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(subtokens)\n",
    "    # Wrap it in a tensor and add an extra batch dimension\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
    "    # Make sure the model does not compute gradients\n",
    "    with torch.no_grad():\n",
    "        # Get the model outputs\n",
    "        outputs = model(input_ids, output_hidden_states=True)\n",
    "    # Check if layer_nums is a list or a single integer\n",
    "    if isinstance(layer_nums, int):\n",
    "        layer_nums = [layer_nums]\n",
    "    # Use the hidden state from the specified layers as word embedding\n",
    "    embeddings = [outputs.hidden_states[i] for i in layer_nums]\n",
    "    # Average the embeddings from the specified layers\n",
    "    averaged_embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "    # Ignore the first and the last token ([CLS] and [SEP])\n",
    "    averaged_embedding = averaged_embedding[0, 1:-1]\n",
    "    # Get the mean of the subtoken vectors to get the word vector\n",
    "    word_embedding = torch.mean(averaged_embedding, dim=0)\n",
    "    # Convert tensor to a numpy array\n",
    "    word_embedding = word_embedding.numpy()\n",
    "    return word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b1ea2c17-a74b-4881-a859-21f8ea897387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(word1, word2, layer_nums):\n",
    "    word1_embedding = get_word_embedding(word1, layer_nums)\n",
    "    word2_embedding = get_word_embedding(word2, layer_nums)\n",
    "    similarity = 1 - cosine(word1_embedding, word2_embedding)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5c7cceba-9582-4498-affb-62cc803909e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'happy'\t'happy'\t1.00\n",
      "'happy'\t'elated'\t0.12\n",
      "'depressed'\t'sad'\t0.32\n",
      "'car'\t'minivan'\t0.24\n",
      "'car'\t'communism'\t0.10\n"
     ]
    }
   ],
   "source": [
    "# similarity queries (default to cosine similarity: 0 least similar, to 1 most similar)\n",
    "pairs = [\n",
    "    ('happy', 'happy'),   # a minivan is a kind of car\n",
    "    ('happy', 'elated'),   # still a wheeled vehicle\n",
    "    ('depressed', 'sad'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'minivan'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, calculate_similarity(w1, w2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b03653-9b0a-4893-8445-eb9f0bd0ae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51f8a5-8cf8-416a-956e-1057a8519c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee74ca5-6c31-4ed1-ae14-7d9a9825a1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2071e0f5-7247-4948-be73-b2cfc0e42c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, BertTokenizerFast\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "994f95d9-5b61-4b15-9eb1-abb453592358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "#model_path = \"C:/Users/kevin/OneDrive - UvA/Y5S2/Text Mining/TM25_Project/TM2025_project/bert_emotion_classifier/model.safetensors\"\n",
    "#config_path = \"C:/Users/kevin/OneDrive - UvA/Y5S2/Text Mining/TM25_Project/TM2025_project/bert_emotion_classifier/config.json\"\n",
    "model_path = \"../TM2025_project/bert_emotion_classifier/model.safetensors\"\n",
    "config_path = \"../TM2025_project/bert_emotion_classifier/config.json\"\n",
    "state_dict = load_file(model_path)\n",
    "config = BertConfig.from_json_file(config_path)\n",
    "model = BertForSequenceClassification(config)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer(\n",
    "    vocab_file=\"../TM2025_project/bert_emotion_classifier/vocab.txt\",\n",
    "    do_lower_case=True,\n",
    "    unk_token=\"[UNK]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    mask_token=\"[MASK]\"\n",
    ")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../TM2025_project/data/preprocessed_letters.csv\")\n",
    "text_column = \"letter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "de67eadb-bf9e-477e-9624-d10c4f656c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset class\n",
    "class LetterDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len=512):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encodings = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {key: val.squeeze(0) for key, val in encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0a3dcc7a-bdda-475a-8df5-7359e2bc46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = LetterDataset(df[text_column].tolist(), tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "41d7e579-c21b-4e6a-bbeb-c1870fec937b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [04:16<00:00,  5.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run predictions\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        outputs = model(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask']\n",
    "        )\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        all_preds.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2d60fd60-8a45-47b1-b65d-e954c6d6eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map predictions to labels\n",
    "id2label = {\n",
    "    int(k): v for k, v in model.config.id2label.items()\n",
    "}\n",
    "df[\"predicted_sentiment\"] = [id2label[p] for p in all_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fdd87228-3df3-4ed7-9724-53bdeefc3e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis completed. Results saved to 'sentiment_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "df.to_csv(\"C:/Users/kevin/OneDrive - UvA/Y5S2/Text Mining/TM25_Project/TM2025_project/sentiment_predictions.csv\", index=False)\n",
    "print(\"Sentiment analysis completed. Results saved to 'sentiment_predictions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a14999-2b9b-4c6b-a651-f156e92224fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
